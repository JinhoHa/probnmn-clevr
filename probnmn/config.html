
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8" />

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-120523111-2"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-120523111-2');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Ubuntu+Mono&display=swap" rel="stylesheet">


    <title>probnmn.config &#8212; ProbNMN 2.0.1 documentation</title>

    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="probnmn.data" href="data.html" />
    <link rel="prev" title="How to evaluate or do inference?" href="usage/evaluation_inference.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-probnmn.config">
<span id="probnmn-config"></span><h1>probnmn.config<a class="headerlink" href="#module-probnmn.config" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="probnmn.config.Config">
<em class="property">class </em><code class="sig-prename descclassname">probnmn.config.</code><code class="sig-name descname">Config</code><span class="sig-paren">(</span><em class="sig-param">config_yaml: str</em>, <em class="sig-param">config_override: List[Any] = []</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/kdexd/probnmn-clevr/blob/master/probnmn/config.py#L6-L272"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#probnmn.config.Config" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This class provides package-wide configuration management. It is a nested dict-like structure
with nested keys accessible as attributes. It contains sensible default values, which can be
modified by (first) a YAML file and (second) a list of attributes and values.</p>
<p>This class definition contains default values corresponding to <code class="docutils literal notranslate"><span class="pre">joint_training</span></code> phase, as it
is the final training phase and uses almost all the configuration parameters. Modification of
any parameter after instantiating this class is not possible, so you must override required
parameter values in either through <code class="docutils literal notranslate"><span class="pre">config_yaml</span></code> file or <code class="docutils literal notranslate"><span class="pre">config_override</span></code> list.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The instantiated object is “immutable” - any modification is prohibited. You must override
required parameter values either through <code class="docutils literal notranslate"><span class="pre">config_file</span></code> or <code class="docutils literal notranslate"><span class="pre">override_list</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>config_yaml: str</strong></dt><dd><p>Path to a YAML file containing configuration parameters to override.</p>
</dd>
<dt><strong>config_override: List[Any], optional (default= [])</strong></dt><dd><p>A list of sequential attributes and values of parameters to override. This happens after
overriding from YAML file.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Let a YAML file named “config.yaml” specify these parameters to override:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ALPHA</span><span class="p">:</span> <span class="mf">1000.0</span>
<span class="n">BETA</span><span class="p">:</span> <span class="mf">0.5</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">_C</span> <span class="o">=</span> <span class="n">Config</span><span class="p">(</span><span class="s2">&quot;config.yaml&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;OPTIM.BATCH_SIZE&quot;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="s2">&quot;BETA&quot;</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_C</span><span class="o">.</span><span class="n">ALPHA</span>  <span class="c1"># default: 100.0</span>
<span class="go">1000.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_C</span><span class="o">.</span><span class="n">BATCH_SIZE</span>  <span class="c1"># default: 256</span>
<span class="go">2048</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_C</span><span class="o">.</span><span class="n">BETA</span>  <span class="c1"># default: 0.1</span>
<span class="go">0.7</span>
</pre></div>
</div>
<dl class="method">
<dt id="probnmn.config.Config.dump">
<code class="sig-name descname">dump</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">file_path:str</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/kdexd/probnmn-clevr/blob/master/probnmn/config.py#L226-L234"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#probnmn.config.Config.dump" title="Permalink to this definition">¶</a></dt>
<dd><p>Save config at the specified file path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>file_path: str</strong></dt><dd><p>(YAML) path to save config at.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="section" id="config-references">
<h2>Config References<a class="headerlink" href="#config-references" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169</pre></div></td><td class="code"><div class="highlight"><pre><span></span>
<span class="c1"># Random seed for NumPy and PyTorch, important for reproducibility.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">RANDOM_SEED</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Which phase to train (or evaluate) on: one of &quot;program_prior&quot;, &quot;question_coding&quot;,</span>
<span class="c1"># &quot;module_training&quot; or &quot;joint_training&quot;.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">PHASE</span> <span class="o">=</span> <span class="s2">&quot;joint_training&quot;</span>

<span class="c1"># Number of training examples where questions have paired ground-truth programs. These</span>
<span class="c1"># examples are chosen randomly (no stochasticity for a fixed `RANDOM_SEED`).</span>
<span class="n">_C</span><span class="o">.</span><span class="n">SUPERVISION</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Maximum length of questions to be considered for choosing subset of training examples.</span>
<span class="c1"># Longer questions will not have paired ground-truth programs by default.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">SUPERVISION_QUESTION_MAX_LENGTH</span> <span class="o">=</span> <span class="mi">40</span>

<span class="c1"># Training objective:</span>
<span class="c1">#   1. &quot;baseline&quot; - only use `SUPERVISION` examples for training (with programs).</span>
<span class="c1">#   2. &quot;ours&quot; - use the whole dataset for training (including examples without programs).</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OBJECTIVE</span> <span class="o">=</span> <span class="s2">&quot;ours&quot;</span>

<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="c1">#   Collection of required data paths for training and evaluation. All these are assumed</span>
<span class="c1">#   to be relative to project root directory.</span>
<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>

<span class="c1"># Path to a directory containing CLEVR v1.0 vocabulary (readable by AllenNLP).</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">VOCABULARY</span> <span class="o">=</span> <span class="s2">&quot;data/clevr_vocabulary&quot;</span>

<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">VAL</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>

<span class="c1"># Path to H5 file containing tokenized programs, questions and answers, and corresponding</span>
<span class="c1"># image indices for CLEVR v1.0 train split.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN_TOKENS</span> <span class="o">=</span> <span class="s2">&quot;data/clevr_train_tokens.h5&quot;</span>

<span class="c1"># Path to H5 file containing pre-extracted features from CLEVR v1.0 train images.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN_FEATURES</span> <span class="o">=</span> <span class="s2">&quot;data/clevr_train_features.h5&quot;</span>

<span class="c1"># Path to H5 file containing tokenized programs, questions and answers, and corresponding</span>
<span class="c1"># image indices for CLEVR v1.0 val split.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">VAL_TOKENS</span> <span class="o">=</span> <span class="s2">&quot;data/clevr_val_tokens.h5&quot;</span>

<span class="c1"># Path to H5 file containing pre-extracted features from CLEVR v1.0 val images.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">VAL_FEATURES</span> <span class="o">=</span> <span class="s2">&quot;data/clevr_val_features.h5&quot;</span>

<span class="c1"># Path to H5 file containing tokenized questions, and corresponding image indices for CLEVR</span>
<span class="c1"># v1.0 test split.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST_TOKENS</span> <span class="o">=</span> <span class="s2">&quot;data/clevr_test_tokens.h5&quot;</span>

<span class="c1"># Path to H5 file containing pre-extracted features from CLEVR v1.0 test images.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST_FEATURES</span> <span class="o">=</span> <span class="s2">&quot;data/clevr_test_features.h5&quot;</span>

<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="c1">#   Model architecture of Program Prior.</span>
<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="n">_C</span><span class="o">.</span><span class="n">PROGRAM_PRIOR</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>

<span class="c1"># The dimension of the inputs to the LSTM.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">PROGRAM_PRIOR</span><span class="o">.</span><span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># The dimension of the outputs of the LSTM.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">PROGRAM_PRIOR</span><span class="o">.</span><span class="n">HIDDEN_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># Number of recurrent layers in the LSTM.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">PROGRAM_PRIOR</span><span class="o">.</span><span class="n">NUM_LAYERS</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Dropout probability for the outputs of LSTM at each layer except last.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">PROGRAM_PRIOR</span><span class="o">.</span><span class="n">DROPOUT</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="c1">#   Model architecture of Program Generator.</span>
<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="n">_C</span><span class="o">.</span><span class="n">PROGRAM_GENERATOR</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>

<span class="c1"># The dimension of the inputs to the encoder and decoder.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">PROGRAM_GENERATOR</span><span class="o">.</span><span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># The dimension of the outputs of the encoder and decoder.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">PROGRAM_GENERATOR</span><span class="o">.</span><span class="n">HIDDEN_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># Number of recurrent layers in the LSTM.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">PROGRAM_GENERATOR</span><span class="o">.</span><span class="n">NUM_LAYERS</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Dropout probability for the outputs of LSTM at each layer except last.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">PROGRAM_GENERATOR</span><span class="o">.</span><span class="n">DROPOUT</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="c1">#   Model architecture of Question Reconstructor.</span>
<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="n">_C</span><span class="o">.</span><span class="n">QUESTION_RECONSTRUCTOR</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>

<span class="c1"># The dimension of the inputs to the encoder and decoder.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">QUESTION_RECONSTRUCTOR</span><span class="o">.</span><span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># The dimension of the outputs of the encoder and decoder.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">QUESTION_RECONSTRUCTOR</span><span class="o">.</span><span class="n">HIDDEN_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># Number of recurrent layers in the LSTM.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">QUESTION_RECONSTRUCTOR</span><span class="o">.</span><span class="n">NUM_LAYERS</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Dropout probability for the outputs of LSTM at each layer except last.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">QUESTION_RECONSTRUCTOR</span><span class="o">.</span><span class="n">DROPOUT</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="c1">#   Model architecture of Neural Module Network.</span>
<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="n">_C</span><span class="o">.</span><span class="n">NMN</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>

<span class="c1"># Shape of input image features, in the form (channel, height, width).</span>
<span class="n">_C</span><span class="o">.</span><span class="n">NMN</span><span class="o">.</span><span class="n">IMAGE_FEATURE_SIZE</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span>
<span class="c1"># Number of channels for each neural module&#39;s convolutional blocks.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">NMN</span><span class="o">.</span><span class="n">MODULE_CHANNELS</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Number of channels in projected final feature map (input to classifier).</span>
<span class="n">_C</span><span class="o">.</span><span class="n">NMN</span><span class="o">.</span><span class="n">CLASS_PROJECTION_CHANNELS</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="c1"># Size of input to the classifier.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">NMN</span><span class="o">.</span><span class="n">CLASSIFIER_LINEAR_SIZE</span> <span class="o">=</span> <span class="mi">1024</span>

<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="c1">#   Loss function co-efficients (names as per paper equations).</span>
<span class="c1"># ----------------------------------------------------------------------------------------</span>

<span class="c1"># Supervision scaling co-efficient. The negative log-likelihood loss of program generation</span>
<span class="c1"># and question reconstruction for examples with (GT) program supervision is scaled by this</span>
<span class="c1"># factor. Used during question coding and joint training.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">ALPHA</span> <span class="o">=</span> <span class="mf">100.0</span>

<span class="c1"># KL co-efficient. KL-divergence in ELBO is scaled by this factor. Used during question</span>
<span class="c1"># coding and joint training.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">BETA</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="c1"># Answer log-likelihood scaling co-efficient during joint training.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">GAMMA</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="c1"># Decay co-efficient for moving average REINFORCE baseline. Used during question coding and</span>
<span class="c1"># joint training.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">DELTA</span> <span class="o">=</span> <span class="mf">0.99</span>

<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="c1">#   Optimization hyper-parameters, relevant during training a particular phase.</span>
<span class="c1">#   Default: Adam optimizer, ReduceLRonPlateau.</span>
<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>

<span class="c1"># Batch size during training and evaluation.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># Number of iterations to train for, batches are randomly sampled.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">NUM_ITERATIONS</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="c1"># Weight decay co-efficient for the optimizer.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="c1"># Initial learning rate for ReduceLROnPlateau.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LR_INITIAL</span> <span class="o">=</span> <span class="mf">0.00001</span>
<span class="c1"># Factor to scale learning rate when an observed metric plateaus.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LR_GAMMA</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="c1"># Number of validation steps to wait and observe improvement in observed metric, before</span>
<span class="c1"># reducing the learning rate.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LR_PATIENCE</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="c1">#   Paths to pre-trained checkpoints of a particular phase to be used in subsequent phases.</span>
<span class="c1"># ----------------------------------------------------------------------------------------</span>
<span class="n">_C</span><span class="o">.</span><span class="n">CHECKPOINTS</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>

<span class="c1"># Program Prior checkpoint, used during question coding and joint training.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">CHECKPOINTS</span><span class="o">.</span><span class="n">PROGRAM_PRIOR</span> <span class="o">=</span> <span class="s2">&quot;checkpoints/program_prior_best.pth&quot;</span>

<span class="c1"># Question coding checkpoint containing Program Prior (unchanged from &quot;program_prior&quot;</span>
<span class="c1"># phase), Program Generator and Question Reconstructor. Used during module training and</span>
<span class="c1"># joint training.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">CHECKPOINTS</span><span class="o">.</span><span class="n">QUESTION_CODING</span> <span class="o">=</span> <span class="s2">&quot;checkpoints/question_coding_1000_ours_best.pth&quot;</span>

<span class="c1"># Module training checkpoint containing Program Generator (unchanged from &quot;question_coding&quot;</span>
<span class="c1"># phase) and Neural Module Network. Used during joint training.</span>
<span class="n">_C</span><span class="o">.</span><span class="n">CHECKPOINTS</span><span class="o">.</span><span class="n">MODULE_TRAINING</span> <span class="o">=</span> <span class="s2">&quot;checkpoints/module_training_1000_ours_best.pth&quot;</span>

</pre></div>
</td></tr></table></div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">ProbNMN</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="usage/setup_dependencies.html">How to setup this codebase?</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage/training.html">How to train your ProbNMN?</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage/evaluation_inference.html">How to evaluate or do inference?</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">probnmn.config</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#config-references">Config References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="data.html">probnmn.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">probnmn.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">probnmn.modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="trainers.html">probnmn.trainers</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluators.html">probnmn.evaluators</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">probnmn.utils</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="usage/evaluation_inference.html" title="previous chapter">How to evaluate or do inference?</a></li>
      <li>Next: <a href="data.html" title="next chapter">probnmn.data</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Karan Desai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.4.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/probnmn/config.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>